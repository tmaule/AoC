{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23925 964373157673\n",
      "Wall time: 96 ms\n"
     ]
    }
   ],
   "source": [
    "# Day 16\n",
    "import numpy as np\n",
    "\n",
    "def parse_rules(rules_list):\n",
    "    rules_dict = dict()\n",
    "    for rule in rules_list:\n",
    "        field, nums = rule.split(': ')\n",
    "        nums = nums.replace(' or ', '-')\n",
    "        nums = list(map(int, nums.split('-')))\n",
    "        nums = list(range(nums[0], nums[1]+1)) + list(range(nums[2], nums[3]+1))\n",
    "        rules_dict[field] = set(nums)\n",
    "    return rules_dict\n",
    "\n",
    "def invalidate_tickets(nearby_tickets, rules):\n",
    "    invalid = list()\n",
    "    valid_nums = set([num for sublist in rules.values() for num in sublist])\n",
    "    rows_to_del = list()\n",
    "    for r in range(nearby_tickets.shape[0]):\n",
    "        for v in nearby_tickets[r]:\n",
    "            if v not in valid_nums:\n",
    "                invalid.append(v)\n",
    "                rows_to_del.append(r)\n",
    "    nearby_tickets = np.delete(nearby_tickets, rows_to_del, axis=0)\n",
    "    return nearby_tickets, invalid\n",
    "\n",
    "def get_this_field(col_num, ticket_matrix, fields_to_check, rules):\n",
    "    for x in ticket_matrix[:,col_num]:\n",
    "        for f in sorted(fields_to_check):\n",
    "            if x not in rules[f]:\n",
    "                fields_to_check.remove(f)        \n",
    "        if len(fields_to_check) == 1:\n",
    "            return next(iter(fields_to_check))\n",
    "\n",
    "def get_field_per_col(rules, nearby_tickets):\n",
    "    field_col_map = dict()\n",
    "    cols_to_assign = set(range(nearby_tickets.shape[1]))\n",
    "    possible_fields = set(rules.keys())\n",
    "    while len(cols_to_assign) > 0:\n",
    "        for c in sorted(cols_to_assign):\n",
    "            fields_to_check = possible_fields.copy()\n",
    "            this_field = get_this_field(c, nearby_tickets, fields_to_check, rules)\n",
    "            if this_field != None:\n",
    "                field_col_map[this_field] = c\n",
    "                possible_fields.remove(this_field)\n",
    "                cols_to_assign.remove(c)\n",
    "    return field_col_map\n",
    "\n",
    "def run(my_file):\n",
    "    data = np.array([x.strip() for x in open(my_file)])\n",
    "    breaks = np.where(data=='')[0]\n",
    "    rules = parse_rules(data[:breaks[0]])\n",
    "    your_ticket = data[breaks[0]+2]\n",
    "    your_ticket = list(map(int, your_ticket.split(',')))\n",
    "    nearby_tickets = data[breaks[1]+2:]\n",
    "    nearby_tickets = np.array([list(map(int, t.split(','))) for t in nearby_tickets])\n",
    "    \n",
    "    nearby_tickets, invalid = invalidate_tickets(nearby_tickets, rules) #pt1\n",
    "    field_col_map = get_field_per_col(rules, nearby_tickets) #pt2\n",
    "#     print(field_col_map)    \n",
    "    pt1 = sum(invalid)\n",
    "    pt2 = 1\n",
    "    for fld in field_col_map:\n",
    "        if 'departure' in fld:\n",
    "            pt2 *= your_ticket[field_col_map[fld]]\n",
    "    print(pt1, pt2)\n",
    "\n",
    "# my_file = 'test.txt'\n",
    "my_file = 'day_16.txt'\n",
    "run(my_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388\n",
      "2280\n"
     ]
    }
   ],
   "source": [
    "# Day 17, CLEAN\n",
    "import numpy as np\n",
    "from scipy.signal import convolve\n",
    "\n",
    "def get_active_cells(myfile, dims=3, cycles=6):\n",
    "    data = [[c == '#' for c in line.strip()] for line in open(my_file)]\n",
    "    grid = np.array(data).astype(int)\n",
    "#     print(grid)\n",
    "    grid = np.expand_dims(grid, axis=tuple(range(dims-2))) #insert a dim of length one for each dim past 2\n",
    "    \n",
    "    #kernel is a generic object length 3 in every dim, i.e. a cube of (3*3*3) surrounding and including active cell in 3D\n",
    "    kernel = np.ones((3, )*dims, dtype=int) \n",
    "    kernel[(1, )*dims] = 0 #zero center of kernel, i.e. don't count active cell; since kernel is len 3 center is 1,1,...\n",
    "    \n",
    "    for _ in range(cycles): #repeat these tasks as many times as asked for\n",
    "        grid = np.pad(grid, pad_width=1, mode='constant', constant_values=0) #pad grid with zeros\n",
    "        #center kernel (hollowed cube of ones) around each cell in the grid, respectively, and multiply where overlap\n",
    "        neighbors = convolve(grid, kernel, mode='same') #output is same size as 'grid', value of each cell is # neighbors\n",
    "        #create bool grids indicating where values need to be changed\n",
    "        set_inactive = np.logical_and(grid == 1, np.floor_divide(neighbors, 2) != 1)\n",
    "        set_active = np.logical_and(grid == 0, neighbors == 3)\n",
    "        #now change those values\n",
    "        grid[set_inactive] = 0\n",
    "        grid[set_active] = 1\n",
    "    print(grid.sum())\n",
    "    \n",
    "# my_file = 'test.txt'\n",
    "my_file = 'day_17.txt'\n",
    "get_active_cells(myfile, dims=3)\n",
    "get_active_cells(myfile, dims=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt1: 388\n"
     ]
    }
   ],
   "source": [
    "# Day 17, Part One, ORIGINAL\n",
    "import numpy as np\n",
    "# my_file = 'test.txt'\n",
    "my_file = 'day_17.txt'\n",
    "\n",
    "data = [[c == '#' for c in line.strip()] for line in open(my_file)]\n",
    "grid = np.array(data).astype(int)\n",
    "\n",
    "grid = grid[:,:,np.newaxis] #convert grid from shape (x,y,0) to (x,y,1)\n",
    "new_shape = np.array(grid.shape) + 2 #provide an extra buffer to avoid boundary checks\n",
    "for n in range(6):\n",
    "    new_shape += 2 #grid can *at most* expand by 2 in each direction per iter\n",
    "    new_grid = np.zeros(new_shape)\n",
    "    s = 2 if n == 0 else 1 #layers of 'slack'\n",
    "    new_grid[s:grid.shape[0]+s, s:grid.shape[1]+s, s:grid.shape[2]+s] = grid.copy()\n",
    "    next_grid = new_grid.copy()\n",
    "    for x in range(1,new_grid.shape[0]-1):\n",
    "        for y in range(1,new_grid.shape[1]-1):\n",
    "            for z in range(1,new_grid.shape[2]-1):\n",
    "                is_active = new_grid[x, y , z] #is this cube currently set to active?\n",
    "                cube_to_check = new_grid[x-1:x+2, y-1:y+2, z-1:z+2]\n",
    "                active_neighbors = int(cube_to_check.sum()) - is_active #don't count yourself!\n",
    "                if is_active:\n",
    "                    if active_neighbors != 2 and active_neighbors != 3:\n",
    "                        next_grid[x, y, z] = 0 #this cell becomes inactive\n",
    "                elif active_neighbors == 3:\n",
    "                    next_grid[x, y, z] = 1 #this cell becomes active (prev inactive)\n",
    "    grid = next_grid.copy()\n",
    "#         print(n, int(grid.sum()))\n",
    "pt1 = grid.sum().astype(int)\n",
    "print(f'pt1: {pt1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt2: 2280\n",
      "Wall time: 843 ms\n"
     ]
    }
   ],
   "source": [
    "# Day 17, Part Two ~840ms\n",
    "import numpy as np\n",
    "# my_file = 'test.txt'\n",
    "my_file = 'day_17.txt'\n",
    "\n",
    "data = [[c == '#' for c in line.strip()] for line in open(my_file)]\n",
    "grid = np.array(data).astype(int)\n",
    "\n",
    "grid = grid[:,:,np.newaxis] #convert grid from shape (x,y,0) to (x,y,1)\n",
    "grid = grid[:,:,:,np.newaxis] #convert grid from shape (x,y,1,0) to (x,y,1,1)\n",
    "new_shape = np.array(grid.shape) + 2 #provide an extra buffer to avoid boundary checks\n",
    "for n in range(6):\n",
    "    new_shape += 2 #grid can *at most* expand by 2 in each direction per iter\n",
    "    new_grid = np.zeros(new_shape)\n",
    "    s = 2 if n == 0 else 1 #layers of 'slack'\n",
    "    new_grid[s:grid.shape[0]+s, s:grid.shape[1]+s, s:grid.shape[2]+s, s:grid.shape[3]+s] = grid.copy()\n",
    "    next_grid = new_grid.copy()\n",
    "    for x in range(1,new_grid.shape[0]-1):\n",
    "        for y in range(1,new_grid.shape[1]-1):\n",
    "            for z in range(1,new_grid.shape[2]-1):\n",
    "                for w in range(1,new_grid.shape[3]-1):\n",
    "                    is_active = new_grid[x, y, z, w] #is this cube currently set to active?\n",
    "                    cube_to_check = new_grid[x-1:x+2, y-1:y+2, z-1:z+2, w-1:w+2]\n",
    "                    active_neighbors = int(cube_to_check.sum()) - is_active #don't count yourself!\n",
    "                    if is_active:\n",
    "                        if active_neighbors != 2 and active_neighbors != 3:\n",
    "                            next_grid[x, y, z, w] = 0 #this cell becomes inactive\n",
    "                    elif active_neighbors == 3:\n",
    "                        next_grid[x, y, z, w] = 1 #this cell becomes active (prev inactive)\n",
    "    grid = next_grid.copy()\n",
    "#         print(n, int(grid.sum()))\n",
    "pt2 = grid.sum().astype(int)\n",
    "print(f'pt2: {pt2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt1: 4491283311856, pt2: 68852578641904\n"
     ]
    }
   ],
   "source": [
    "#Day 18\n",
    "import numpy as np\n",
    "\n",
    "def clean_line(line):\n",
    "    line = line.replace('(', '( ')\n",
    "    line = line.replace(')', ' )')\n",
    "    return line.split(' ')\n",
    "\n",
    "def eval_chunk(chunk):\n",
    "    while len(chunk) != 1:\n",
    "        res = eval(''.join(chunk[0:3]))\n",
    "        del chunk[0:3]\n",
    "        chunk.insert(0, str(res))\n",
    "    return chunk[0]\n",
    "\n",
    "def eval_chunk2(chunk):\n",
    "    while len(chunk) != 1:\n",
    "        if '+' in chunk:\n",
    "            i = chunk.index('+')\n",
    "        elif '*' in chunk:\n",
    "            i = chunk.index('*')\n",
    "        res = eval(''.join(chunk[i-1:i+2]))\n",
    "        del chunk[i-1:i+2]\n",
    "        chunk.insert(i-1, str(res))\n",
    "    return chunk[0]\n",
    "\n",
    "def simplify_all_parens(chars1):\n",
    "    chars2 = chars1.copy()\n",
    "    while ')' in chars1:\n",
    "        cp_idx = chars1.index(')') #find first closed paren\n",
    "        len_chunk = chars1[cp_idx::-1].index('(')\n",
    "        op_idx = cp_idx - len_chunk\n",
    "        chunk_val1 = eval_chunk(chars1[op_idx+1:cp_idx])\n",
    "        chunk_val2 = eval_chunk2(chars2[op_idx+1:cp_idx])\n",
    "        del chars1[op_idx:cp_idx+1]\n",
    "        del chars2[op_idx:cp_idx+1]\n",
    "        chars1.insert(op_idx, chunk_val1)\n",
    "        chars2.insert(op_idx, chunk_val2)\n",
    "    return chars1, chars2\n",
    "\n",
    "def run(my_file):\n",
    "    data = [x.strip() for x in open(my_file)]\n",
    "    results_by_line = np.array([[],[]], dtype=int) #a (truly) empty array shape 2,1\n",
    "    for line in data:\n",
    "        #get a list of all nums/operators, incl parens\n",
    "        all_chars = clean_line(line)\n",
    "        #simplify away all the parens\n",
    "        chars1, chars2 = simplify_all_parens(all_chars)\n",
    "        #eval what remains\n",
    "        new_res = np.array([[int(eval_chunk(chars1))], [int(eval_chunk2(chars2))]]) #pt1, pt2, in shape 2,1\n",
    "        results_by_line = np.hstack((results_by_line, new_res)) #tack on to our running totals\n",
    "    return results_by_line[0,:].sum(), results_by_line[1,:].sum()\n",
    "\n",
    "# my_file = 'test.txt'\n",
    "my_file = 'day_18.txt'\n",
    "pt1, pt2 = run(my_file)\n",
    "print(f'pt1: {pt1}, pt2: {pt2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt1: 111, pt2: 343\n"
     ]
    }
   ],
   "source": [
    "#Day 19\n",
    "def initialize(data):\n",
    "    rules = dict() #r_num (str) --> set of all letter permutations which satisfy\n",
    "    dependents = dict() #r_num (str) --> set of all other rules which need to be defined first\n",
    "    sequences = dict() #r_num (str) --> list of possible orderings of other rules (could be one or two)\n",
    "    messages = list()    \n",
    "    for line in data:\n",
    "        if line != '' and line[0].isnumeric():\n",
    "            r_num, seqs = line.split(': ')\n",
    "            if seqs[0] == '\"':\n",
    "                rules[r_num] = {seqs.strip('\"')}\n",
    "            else:\n",
    "                if '|' in seqs:\n",
    "                    seqs = seqs.split(' | ')\n",
    "                    for i in range(len(seqs)):\n",
    "                        seqs[i] = seqs[i].split(' ')\n",
    "                else:\n",
    "                    seqs = [seqs.split(' ')]\n",
    "                dependents[r_num] = set()\n",
    "                sequences[r_num] = list()\n",
    "                for s in seqs:\n",
    "                    sequences[r_num].append(s)\n",
    "                    for r in s:\n",
    "                        dependents[r_num].add(r)\n",
    "        elif line != '':\n",
    "            messages.append(line)\n",
    "    return rules, dependents, sequences, messages\n",
    "\n",
    "def valid_for_pt2(msg, rule42, rule31, len42):\n",
    "    #new rules for pt2: {'8':'42 | 42 8', '11':'42 31 | 42 11 31'}\n",
    "    #this means that additionally valid strings would:\n",
    "    #(1) begin with any # of consecutive chunks which are valid for rule42\n",
    "    #(2) end with some # of consecutive rule31 chunks, but this must be at least one fewer in length than the 42s @ start\n",
    "    chunks = [msg[i:i+len42] for i in range(0, len(msg), len42)]\n",
    "    chunk_rules = [(c in rule42)*42 + (c in rule31)*31 for c in chunks]\n",
    "    if chunk_rules[0] == 42 and 31 in chunk_rules and 0 not in chunk_rules:\n",
    "        if chunk_rules[chunk_rules.index(31):].count(42) == 0 and chunk_rules.count(31) < chunk_rules.count(42):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def run(my_file):\n",
    "    data = [x.strip() for x in open(my_file)]\n",
    "    #interpret data, create the dictionaries we will use to trace rules\n",
    "    rules, dependents, sequences, messages = initialize(data)\n",
    "    #solve any rules which already have all dependents, repeat until no dependents remain\n",
    "    while dependents != dict():\n",
    "        for r_num in sorted(dependents):\n",
    "            if all([d in rules for d in dependents[r_num]]):\n",
    "                rules[r_num] = set()\n",
    "                for seq in sequences[r_num]:\n",
    "                    poss_strs = {0:list(), 1:list(), 2:list()}\n",
    "                    if len(seq) < 3:\n",
    "                        poss_strs[2] = ['']\n",
    "                    if len(seq) < 2:\n",
    "                        poss_strs[1] = ['']\n",
    "                    for i in range(len(seq)):\n",
    "                        for str_ in rules[seq[i]]:\n",
    "                            poss_strs[i].append(str_)\n",
    "                    for str0 in poss_strs[0]:\n",
    "                        for str1 in poss_strs[1]:\n",
    "                            for str2 in poss_strs[2]:\n",
    "                                rules[r_num].add(str0+str1+str2)\n",
    "                dependents.pop(r_num, None)\n",
    "    rule42 = rules['42'] #need these for pt2\n",
    "    rule31 = rules['31']\n",
    "    len42 = len(next(iter(rule42))) #assume rules 42/31 same len\n",
    "    pt1, pt2 = 0, 0\n",
    "    for msg in messages:\n",
    "        if msg in rules['0']:\n",
    "            pt1 += 1   \n",
    "        elif valid_for_pt2(msg, rule42, rule31, len42):\n",
    "            pt2 += 1\n",
    "    return pt1, pt1+pt2\n",
    "\n",
    "# my_file = 'test.txt'\n",
    "my_file = 'day_19.txt'\n",
    "pt1, pt2 = run(my_file)\n",
    "print(f'pt1: {pt1}, pt2: {pt2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt1: 16192267830719, pt2: 1909\n"
     ]
    }
   ],
   "source": [
    "# Day 20 --Jurrassic Jigsaw--\n",
    "import numpy as np\n",
    "from scipy.signal import convolve\n",
    "    \n",
    "def get_match(edge, all_edges, tile_id):\n",
    "    #check if there is a match for this edge(besides itself), or for the reverse of this edge\n",
    "    rev_edge = edge[::-1]\n",
    "    if edge.tobytes() in all_edges:\n",
    "        for t_id in all_edges[edge.tobytes()]:\n",
    "            if t_id != tile_id:\n",
    "                return t_id\n",
    "    if rev_edge.tobytes() in all_edges:\n",
    "        for t_id in all_edges[rev_edge.tobytes()]:\n",
    "            if t_id != tile_id:\n",
    "                return t_id\n",
    "\n",
    "def get_dicts(tiles):\n",
    "    all_edges = dict()\n",
    "    id_edges_map = dict()\n",
    "    id_grid_map = dict()\n",
    "    for tile in tiles:\n",
    "        if tile == '': #EoF condition\n",
    "            continue\n",
    "        lines = tile.split('\\n')\n",
    "        grid = [[c == '#' for c in line] for line in lines[1:]]\n",
    "        grid = np.array(grid).astype(int)\n",
    "        tile_id = int(lines[0].strip('Tile ').strip(':'))\n",
    "        edges = [grid[0,:], grid[-1,:], grid[:,0], grid[:,-1]]\n",
    "        id_edges_map[tile_id] = edges\n",
    "        id_grid_map[tile_id] = grid\n",
    "        for edge in edges:\n",
    "            if edge.tobytes() in all_edges:\n",
    "                all_edges[edge.tobytes()].append(tile_id)\n",
    "            else:\n",
    "                all_edges[edge.tobytes()] = [tile_id]\n",
    "    return all_edges, id_edges_map, id_grid_map\n",
    "\n",
    "def get_corners(id_edges_map, all_edges):\n",
    "    corners = list()\n",
    "    for tile_id in id_edges_map:\n",
    "        matched_edges = 0\n",
    "        for edge in id_edges_map[tile_id]:\n",
    "            if get_match(edge, all_edges, tile_id) != None: \n",
    "                matched_edges += 1\n",
    "        if matched_edges == 2:\n",
    "            corners.append(tile_id)\n",
    "    return corners\n",
    "\n",
    "def create_supergrid(id_grid_map, all_edges, seed):\n",
    "    side_len = np.sqrt(len(id_grid_map)).astype(int)\n",
    "    seed_grid = id_grid_map[seed].copy()\n",
    "    #force matches to occur on bottom, right\n",
    "    if get_match(seed_grid[0,:], all_edges, seed) is not None:\n",
    "        seed_grid = np.flip(seed_grid, 0)\n",
    "    if get_match(seed_grid[:,0], all_edges, seed) is not None:\n",
    "        seed_grid = np.flip(seed_grid, 1)\n",
    "#     print('first seed:', seed)\n",
    "    row_seeds = [seed]\n",
    "    row_grids = {seed:seed_grid}\n",
    "    for _ in range(side_len-1):\n",
    "        curr_bottom = seed_grid[-1,:]\n",
    "        next_seed = get_match(curr_bottom, all_edges, seed)\n",
    "#         print('next seed:', next_seed)\n",
    "        next_seed_grid = id_grid_map[next_seed].copy()\n",
    "        next_top = next_seed_grid[0,:]\n",
    "        while not np.array_equal(curr_bottom, next_top):\n",
    "            if np.array_equal(curr_bottom, next_top[::-1]):\n",
    "                next_seed_grid = np.flip(next_seed_grid, 1)\n",
    "            else:\n",
    "                next_seed_grid = np.rot90(next_seed_grid)\n",
    "            next_top = next_seed_grid[0,:]\n",
    "        row_seeds.append(next_seed)\n",
    "        row_grids[next_seed] = next_seed_grid\n",
    "        seed = next_seed\n",
    "        seed_grid = next_seed_grid.copy()\n",
    "    rows = []\n",
    "    for this_tile in row_seeds:\n",
    "#         print('-START ROW-', this_tile)\n",
    "        row = row_grids[this_tile]\n",
    "        for _ in range(side_len-1):\n",
    "            curr_rt = row[:,-1]\n",
    "            next_tile = get_match(curr_rt, all_edges, this_tile)\n",
    "            this_tile = next_tile\n",
    "#             print('next tile:', next_tile)\n",
    "            next_tile_grid = id_grid_map[next_tile].copy()\n",
    "            next_left = next_tile_grid[:,0]\n",
    "            while not np.array_equal(curr_rt, next_left):\n",
    "                if np.array_equal(curr_rt, next_left[::-1]):\n",
    "                    next_tile_grid = np.flip(next_tile_grid, 0)\n",
    "                else:\n",
    "                    next_tile_grid = np.rot90(next_tile_grid)\n",
    "                next_left = next_tile_grid[:,0]\n",
    "            row = np.hstack((row, next_tile_grid))\n",
    "        rows.append(row)\n",
    "    supergrid = rows[0]\n",
    "    for row in rows[1:]:\n",
    "        supergrid = np.vstack((supergrid,row))\n",
    "    idx_to_del = list(range(0,supergrid.shape[0],10))+list(range(9,supergrid.shape[0],10))\n",
    "    supergrid = np.delete(supergrid, idx_to_del, axis=0)\n",
    "    supergrid = np.delete(supergrid, idx_to_del, axis=1)\n",
    "    return supergrid\n",
    "\n",
    "def find_monsters(supergrid):\n",
    "    monster = np.zeros((3,20)).astype(int)\n",
    "    monster[0,18] = 1\n",
    "    monster[1,[0,5,6,11,12,17,18,19]] = 1\n",
    "    monster[2,[1,4,7,10,13,16]] = 1\n",
    "    overlap = convolve(supergrid, monster, mode='same')\n",
    "    num_monsters = np.sum(overlap == monster.sum())\n",
    "    iters = 0\n",
    "    while num_monsters == 0:\n",
    "        iters += 1\n",
    "        supergrid = np.rot90(supergrid)\n",
    "        if iters % 4 == 0: #every fourth go, rotate back to original, then flip\n",
    "            supergrid = np.flip(supergrid, 1)\n",
    "        overlap = convolve(supergrid, monster, mode='same')\n",
    "        num_monsters = np.sum(overlap == monster.sum())\n",
    "#     print(iters, num_monsters)\n",
    "    return supergrid.sum() - num_monsters*monster.sum()\n",
    "\n",
    "def run(my_file):\n",
    "    tiles = open(my_file).read().split('\\n\\n')\n",
    "    #get(1)dict of unique edge -> [ids w/that edge] (2)map of each tile_id to its four edges(as arrays) (3)all grids\n",
    "    all_edges, id_edges_map, id_grid_map = get_dicts(tiles) \n",
    "    #find tiles that only have two edges which match another edge, call these corners\n",
    "    corners = get_corners(id_edges_map, all_edges)\n",
    "    supergrid = create_supergrid(id_grid_map, all_edges, corners[0])\n",
    "#     print(supergrid.sum())\n",
    "    pt2 = find_monsters(supergrid) #sum number of '#' in grid which are *not* part of a monster\n",
    "    return np.prod(np.array(corners).astype(float)), pt2\n",
    "    \n",
    "# my_file = 'test.txt'\n",
    "my_file = 'day_20.txt'\n",
    "pt1, pt2 = run(my_file)\n",
    "print(f'pt1: {int(pt1)}, pt2: {pt2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
